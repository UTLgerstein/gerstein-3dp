{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b388db47",
   "metadata": {},
   "source": [
    "Check that colab is using a GPU then install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a969d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found - using CPU (will be slow)\")\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nInstalling packages...\")\n",
    "!pip install -q nnunetv2 SimpleITK nibabel numpy-stl scikit-image\n",
    "\n",
    "# Create input directory\n",
    "os.makedirs('/content/input', exist_ok=True)\n",
    "os.makedirs('/content/output', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3a040",
   "metadata": {},
   "source": [
    "Install models from hugging face and the nnu-net inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Huggingface model download\n",
    "!pip install -q huggingface_hub\n",
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(repo_id=\"aagatti/nnunet_knee\", local_dir=\"./nnunet_knee_models\")\n",
    "\n",
    "# Clone inference repository\n",
    "!git clone https://github.com/gattia/nnunet_knee_inference.git /content/nnunet_knee_inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f987a39",
   "metadata": {},
   "source": [
    "Upload MRI files from computer (.nii format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a36b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"üì§ Please select your knee_001.nii file to upload:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to input directory\n",
    "for filename in uploaded.keys():\n",
    "    shutil.move(filename, f'/content/input/{filename}')\n",
    "    print(f\"‚úì Uploaded: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/nnunet_knee_inference')\n",
    "\n",
    "from scripts.inference import KneeSegmentationInference\n",
    "\n",
    "# Initialize the inference\n",
    "print(\"Loading model...\")\n",
    "inference = KneeSegmentationInference(\n",
    "    model_dir=\"/content/nnunet_knee_model\"\n",
    ")\n",
    "\n",
    "# Get the input file name\n",
    "input_files = os.listdir('/content/input')\n",
    "if len(input_files) == 0:\n",
    "    print(\"‚ùå No input files found!\")\n",
    "else:\n",
    "    input_file = input_files[0]\n",
    "    input_path = f'/content/input/{input_file}'\n",
    "    output_path = f'/content/output/{input_file.replace(\".nii\", \"_seg.nii.gz\")}'\n",
    "    \n",
    "    print(f\"Processing: {input_file}\")\n",
    "    print(\"‚è≥ This will take 5-10 minutes with GPU, 20-30 minutes with CPU...\")\n",
    "    \n",
    "    # Run prediction\n",
    "    result = inference.predict(input_path, output_path)\n",
    "    \n",
    "    print(f\"‚úì Segmentation complete!\")\n",
    "    print(f\"Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b90669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# List output files\n",
    "print(\"Available output files:\")\n",
    "output_files = os.listdir('/content/output')\n",
    "for f in output_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Download the segmentation\n",
    "if len(output_files) > 0:\n",
    "    output_file = output_files[0]\n",
    "    output_path = f'/content/output/{output_file}'\n",
    "    \n",
    "    print(f\"\\nüì• Downloading: {output_file}\")\n",
    "    files.download(output_path)\n",
    "    print(\"‚úì Download complete!\")\n",
    "else:\n",
    "    print(\"‚ùå No output files found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
